import os
import io
import json
import numpy as np
import pandas as pd
import streamlit as st
import tensorflow as tf
from tensorflow.keras import layers
import joblib

# =========================================
#  Custom layers / model (MUST match training)
# =========================================
@tf.keras.utils.register_keras_serializable(package="custom")
class GraphAttentionLayer(tf.keras.layers.Layer):
    def __init__(self, out_dim, dropout_rate=0.1, **kwargs):
        super().__init__(**kwargs)
        self.out_dim = out_dim
        self.dropout_rate = dropout_rate

    def build(self, input_shape):
        h_shape = input_shape[0] if isinstance(input_shape, (list, tuple)) else input_shape
        in_dim = h_shape[-1]
        self.W = self.add_weight(shape=(in_dim, self.out_dim), initializer='glorot_uniform', trainable=True, name='W')
        self.a = self.add_weight(shape=(2*self.out_dim, 1), initializer='glorot_uniform', trainable=True, name='a')
        self.leaky_relu = tf.keras.layers.LeakyReLU(0.2)
        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)

    def call(self, inputs, training=False):
        h, adj = inputs
        Wh = tf.matmul(h, self.W)
        N  = tf.shape(adj)[-1]
        Wh1 = tf.repeat(tf.expand_dims(Wh, 1), repeats=N, axis=1)
        Wh2 = tf.repeat(tf.expand_dims(Wh, 2), repeats=N, axis=2)
        e = self.leaky_relu(tf.squeeze(tf.matmul(tf.concat([Wh1, Wh2], -1), self.a), -1))
        attn = tf.nn.softmax(e, axis=-1)
        attn = self.dropout(attn, training=training)
        attn = attn * adj
        attn = attn / (tf.reduce_sum(attn, axis=-1, keepdims=True) + 1e-9)
        return tf.matmul(attn, Wh)

    def get_config(self):
        return {**super().get_config(),
                "out_dim": self.out_dim, "dropout_rate": self.dropout_rate}
    @classmethod
    def from_config(cls, config):
        return cls(**config)
        
@tf.keras.utils.register_keras_serializable(package="custom")
class SelfAttentionEncoder(tf.keras.layers.Layer):
    def __init__(self, dim_in, dim_hidden, dim_proj=64, n_heads=4, dropout=0.1, **kwargs):
        super().__init__(**kwargs)
        self.dim_in, self.dim_hidden = dim_in, dim_hidden
        self.dim_proj, self.n_heads, self.dropout = dim_proj, n_heads, dropout
        
        self.proj = layers.Dense(dim_proj)
        self.attn = layers.MultiHeadAttention(num_heads=n_heads, key_dim=dim_proj // n_heads, dropout=dropout)
        self.norm = layers.LayerNormalization()
        self.ff = tf.keras.Sequential([layers.Dense(dim_hidden, activation='relu')])

    def call(self, x, training=False):
        x = tf.expand_dims(self.proj(x), axis=1)
        attn_out = self.attn(x, x, x, training=training)
        x = self.norm(attn_out)
        return self.ff(x[:, 0])

    def get_config(self):
        return {**super().get_config(),
                "dim_in": self.dim_in, "dim_hidden": self.dim_hidden,
                "dim_proj": self.dim_proj, "n_heads": self.n_heads, "dropout": self.dropout}
    @classmethod
    def from_config(cls, config):
        return cls(**config)
        
@tf.keras.utils.register_keras_serializable(package="custom")
class HeteroGNN(tf.keras.Model):
    def __init__(self, num_p, num_v, num_s, num_e, dim_hidden=64, ff_dim=128, dropout=0.1, **kwargs):
        super().__init__(**kwargs)
        self._init_kwargs = dict(num_p=num_p, num_v=num_v, num_s=num_s, num_e=num_e, dim_hidden=dim_hidden, ff_dim=ff_dim, dropout=dropout)
        self.encoder_p = SelfAttentionEncoder(num_p, dim_hidden, dropout=dropout)
        self.encoder_v = SelfAttentionEncoder(num_v, dim_hidden, dropout=dropout)
        self.encoder_s = SelfAttentionEncoder(num_s, dim_hidden, dropout=dropout)
        self.encoder_e = SelfAttentionEncoder(num_e, dim_hidden, dropout=dropout)
        self.gat = GraphAttentionLayer(out_dim=dim_hidden, dropout_rate=dropout)
        self.mlp = tf.keras.Sequential([
            layers.Input(shape=(dim_hidden * 4,)),
            layers.Dropout(dropout),
            layers.Dense(ff_dim, activation='relu'),
            layers.Dropout(dropout),
            layers.Dense(1)
        ])
        self.A_logits = self.add_weight(shape=(4, 4), initializer='glorot_uniform', trainable=True, name='adj_logits')

    def call(self, inputs, training=False):
        x_p, x_v, x_s, x_e = inputs
        h_p = self.encoder_p(x_p, training=training)
        h_v = self.encoder_v(x_v, training=training)
        h_s = self.encoder_s(x_s, training=training)
        h_e = self.encoder_e(x_e, training=training)
        h_nodes = tf.stack([h_p, h_v, h_s, h_e], axis=1)
        A_prob = tf.sigmoid(self.A_logits)
        A_sym  = 0.5 * (A_prob + tf.transpose(A_prob))
        I = tf.eye(4, dtype=A_sym.dtype)
        A_sym = A_sym * (1.0 - I) + 1e-3 * I
        B = tf.shape(h_nodes)[0]
        adj_batch = tf.broadcast_to(A_sym, (B, 4, 4))
        h_gnn = self.gat((h_nodes, adj_batch), training=training)
        h_flat = tf.reshape(h_gnn, (B, -1))
        return self.mlp(h_flat)[:, 0]

    def get_config(self):
        # Keras ê¸°ë³¸ í•„ë“œ + ìš°ë¦¬ê°€ í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°
        return {**super().get_config(), **self._init_kwargs}

    @classmethod
    def from_config(cls, config):
        return cls(**config)

# =========================================
# Config: file paths & category mapping
# =========================================
DEFAULT_MODEL_PATH = "revised_GAT_model_fold1.keras" # repoì— í¬í•¨
DEFAULT_SCALER_PATH = "scaler_params.json" # repoì— í¬í•¨ (JSON or joblib)

# ì¹´í…Œê³ ë¦¬ ë¼ë²¨ ë§¤í•‘ì„ ì½”ë“œì— ì§ì ‘ ë‚´ì¥(í›ˆë ¨ ì‹œ LabelEncoder ê²°ê³¼ì™€ ì¼ì¹˜í•´ì•¼ í•¨)
# ì¹´í…Œê³ ë¦¬ ë¼ë²¨ ë§¤í•‘(í›ˆë ¨ ì‹œ LabelEncoder ê²°ê³¼ì™€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•¨)
LABEL_MAPS = {
"Skin Type": {"human": 1, "pig": 2, "rat": 3, "guineapig": 4, "mouse": 5, "rabbit": 6},
"Vcl_LP": {"hydrophilic": 0, "lipophilic": 1},
"Corrosive_Irritation_score": {"Negative": 0, "Positive": 1},
"Emulsifier": {"Not Include Emulsifier": 0, "Include Emulsifier": 1},
}
# ê²°ì¸¡/ë¯¸ì„ íƒ ì‹œ ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ (UI ê¸°ë³¸ê°’)
DEFAULT_LABELS = {
"Skin Type": "human",
"Vcl_LP": "lipophilic",
"Corrosive_Irritation_score": "Positive",
"Emulsifier": "Include Emulsifier",
}

# ğŸ”¹ ì—¬ê¸°ì— í™”í•™ë¬¼ì§ˆ DB ê²½ë¡œ & ë¡œë” ì¶”ê°€
PROCESSED_XLSX = "processed_test_target.xlsx"  # ë ˆí¬ì— í•¨ê»˜ ì˜¬ë ¤ë‘ê¸° (xlsx)

@st.cache_resource
def load_chemical_db(path: str):
    if not os.path.exists(path):
        st.warning(f"í™”í•™ë¬¼ì§ˆ DB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
        return None
    try:
        # pandasê°€ xlsx ì½ìœ¼ë ¤ë©´ requirementsì— openpyxl í•„ìš”
        return pd.read_excel(path)
    except Exception as e:
        st.error(f"xlsx ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

# =========================================
#  Utilities to load model & scaler (no upload)
# =========================================
CUSTOM_OBJECTS = {
    "HeteroGNN": HeteroGNN,
    "SelfAttentionEncoder": SelfAttentionEncoder,
    "GraphAttentionLayer": GraphAttentionLayer,
}

@st.cache_resource
def load_model_from_disk(path: str):
    if not os.path.exists(path):
        st.error(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
        st.stop()
    try:
        return tf.keras.models.load_model(
            path,
            custom_objects=CUSTOM_OBJECTS,
            compile=False,      # ì˜µí‹°ë§ˆì´ì €/ë©”íŠ¸ë¦­ ë³µì› ì•ˆí•¨
            safe_mode=False,    # ì»¤ìŠ¤í…€ ì½”ë“œ ì‹¤í–‰ í—ˆìš© (Keras3ì—ì„œ ì¤‘ìš”)
        )
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()

@st.cache_resource
def load_scaler_params_from_disk(path: str):
    if not os.path.exists(path):
        st.error(f"ìŠ¤ì¼€ì¼ëŸ¬ íŒŒë¼ë¯¸í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
        st.stop()
    # joblib bundle ì§€ì›
    if path.endswith('.joblib') or path.endswith('.pkl'):
        bundle = joblib.load(path)
        if isinstance(bundle, dict) and 'scaler' in bundle and 'cols' in bundle:
            scaler = bundle['scaler']
            cols = bundle['cols']
            df = pd.DataFrame({'mean': scaler.mean_, 'std': scaler.scale_}, index=cols)
            return df[['mean','std']]
        else:
            st.error('joblib íŒŒì¼ì€ {"scaler": StandardScaler, "cols": [...]} í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.')
            st.stop()
    # json (orient='table' ë˜ëŠ” dict)
    with open(path, 'rb') as f:
        content = f.read()
    try:
        obj = json.loads(content)
        if isinstance(obj, dict) and 'schema' in obj and 'data' in obj:
            df = pd.read_json(io.BytesIO(content), orient='table')
            if 'feature' in df.columns:
                df = df.set_index('feature')
            return df[['mean','std']]
        elif isinstance(obj, dict):
            rows = []
            for k, v in obj.items():
                rows.append({'feature': k, 'mean': v.get('mean', 0.0), 'std': v.get('std', 1.0)})
            df = pd.DataFrame(rows).set_index('feature')
            return df[['mean','std']]
    except Exception:
        pass
    st.error('ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¤ì¼€ì¼ëŸ¬ íŒŒë¼ë¯¸í„° í˜•ì‹ì…ë‹ˆë‹¤. JSON(param_df) ë˜ëŠ” joblib ë²ˆë“¤ì„ ì‚¬ìš©í•˜ì„¸ìš”.')
    st.stop()


def standardize_from_params(raw_dict, params_df):
    out = {}
    for feat, row in params_df.iterrows():
        mean = float(row['mean'])
        std  = float(row['std']) if row['std'] != 0 else 1e-9
        x    = float(raw_dict.get(feat, 0.0))
        out[f'scaled_{feat}'] = (x - mean) / std
    return out

# ì•„ì›ƒë¼ì´ì–´ ìë¥´ê¸°
OUTLIERS_XLSX = "outliers.xlsx"
CLIP_COLS = ['Molecular Weight', 'Density', 'Melting Point',
             'Boiling Point', 'Water Solubility', 'Vapor Pressure']

@st.cache_resource
def load_outlier_limits(path: str, clip_cols=None):
    """
    ìƒˆ í˜•ì‹:
      - ë‹¨ì¼ ì‹œíŠ¸(ê¸°ë³¸ Sheet1)
      - 0í–‰: upper(ìƒí•œ), 1í–‰: lower(í•˜í•œ)
      - ì»¬ëŸ¼: feature ëª…
    êµ¬í˜• í˜•ì‹(ë°±ì›Œë“œ í˜¸í™˜):
      - 'upper' / 'lower' ì‹œíŠ¸, ê° ì‹œíŠ¸ì˜ 1í–‰ì— ê°’
    ë°˜í™˜: { feature: (lower, upper) }
    """
    if not os.path.exists(path):
        st.warning(f"outliers íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
        return {}

    def _clean(df: pd.DataFrame) -> pd.DataFrame:
        # to_excel ê¸°ë³¸ ì¸ë±ìŠ¤ ì—´ ì œê±°
        drop_cols = [c for c in df.columns if str(c).startswith("Unnamed")]
        if drop_cols:
            df = df.drop(columns=drop_cols)
        # ëª¨ë“  ê°’ì„ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„ (ë¬¸ì ì €ì¥ ëŒ€ë¹„)
        for c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
        return df

    try:
        # 1) ìƒˆ í˜•ì‹ ì‹œë„ (ë‹¨ì¼ ì‹œíŠ¸, 0:upper / 1:lower)
        df = _clean(pd.read_excel(path))  # ì²« ì‹œíŠ¸
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê¸°(ìˆì„ ë•Œ)
        if clip_cols:
            keep = [c for c in df.columns if c in clip_cols]
            if keep:
                df = df[keep]
        if len(df) >= 2 and df.shape[1] > 0:
            upper_row = df.iloc[0]
            lower_row = df.iloc[1]
            limits = {}
            for feat in df.columns:
                hi = upper_row.get(feat)
                lo = lower_row.get(feat)
                hi = float(hi) if pd.notna(hi) else None
                lo = float(lo) if pd.notna(lo) else None
                limits[str(feat).strip()] = (lo, hi)  # (lower, upper)
            # ìƒˆ í˜•ì‹ì´ ìœ íš¨í•˜ë©´ ë°”ë¡œ ë°˜í™˜
            if any(v is not None for pair in limits.values() for v in pair):
                return limits

        # 2) êµ¬í˜• í˜•ì‹ í´ë°± (upper/lower ì‹œíŠ¸)
        xls = pd.ExcelFile(path)
        if set(["upper", "lower"]).issubset(set(xls.sheet_names)):
            df_u = _clean(pd.read_excel(xls, sheet_name="upper"))
            df_l = _clean(pd.read_excel(xls, sheet_name="lower"))
            if not df_u.empty:
                row_u = df_u.iloc[0]
            else:
                row_u = pd.Series(dtype=float)
            if not df_l.empty:
                row_l = df_l.iloc[0]
            else:
                row_l = pd.Series(dtype=float)
            # êµì§‘í•© ì»¬ëŸ¼ë§Œ
            cols = set(row_u.index) | set(row_l.index)
            if clip_cols:
                cols &= set(clip_cols)
            limits = {}
            for feat in cols:
                hi = row_u.get(feat)
                lo = row_l.get(feat)
                hi = float(hi) if pd.notna(hi) else None
                lo = float(lo) if pd.notna(lo) else None
                limits[str(feat).strip()] = (lo, hi)
            return limits

        st.error("outliers.xlsx í˜•ì‹ì„ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    except Exception as e:
        st.error(f"outliers.xlsx ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

def clip_with_limits(feat: str, val: float, limits: dict):
    """limits(dict) ì•ˆì˜ (lower, upper)ë¡œ ê°’ í´ë¦¬í•‘."""
    if feat not in limits:
        return val, None
    lo, hi = limits[feat]
    clipped = val
    if lo is not None:
        clipped = max(clipped, lo)
    if hi is not None:
        clipped = min(clipped, hi)
    changed = (clipped != val)
    return clipped, (lo, hi) if changed else None

# -------------------------------
# Skin Thickness ê·œì¹™/ì˜µì…˜
# -------------------------------
SKIN_SITE_CANON = {
    "rat": ["abdominal", "dorsal"],
    "human": ["abdominal", "dorsal", "breast", "abdominal or breast",
              "abdominal or breast or forearm", "ears", "forearm"],
    "pig": ["dorsal", "ears"],
    "guineapig": ["dorsal"],
    "rabbit": ["dorsal"],
    "mouse": ["dorsal"],  # ê·œì¹™ ë¯¸ì • â†’ ê¸°ë³¸ê°’ ì—†ìŒ
}

SKIN_THICKNESS_RULES = {
    ("rat", "abdominal", "whole"): 1440.0,
    ("rat", "abdominal", "epidermis"): 11.58,
    ("rat", "dorsal", "whole"): 1830.0,
    ("rat", "dorsal", "epidermis"): 21.66,

    ("human", "ears", "whole"): 1399.83,
    ("human", "ears", "epidermis"): 84.96,
    ("human", "forearm", "whole"): 1500.0,
    ("human", "forearm", "epidermis"): 36.0,
    ("human", "abdominal", "whole"): 2775.0,
    ("human", "abdominal", "epidermis"): 49.05,
    ("human", "dorsal", "whole"): 2775.0,
    ("human", "dorsal", "epidermis"): 49.05,
    ("human", "breast", "whole"): 2775.0,
    ("human", "breast", "epidermis"): 49.05,
    ("human", "abdominal or breast", "whole"): 2775.0,
    ("human", "abdominal or breast", "epidermis"): 49.05,
    ("human", "abdominal or breast or forearm", "whole"): 2775.0,
    ("human", "abdominal or breast or forearm", "epidermis"): 49.05,

    ("pig", "dorsal", "whole"): 3400.0,
    ("pig", "dorsal", "epidermis"): 66.0,
    ("pig", "ears", "whole"): 1300.0,
    ("pig", "ears", "epidermis"): 50.0,

    ("guineapig", "dorsal", "whole"): 1150.0,
    ("guineapig", "dorsal", "epidermis"): 20.8,

    ("rabbit", "dorsal", "whole"): 1830.0,
    ("rabbit", "dorsal", "epidermis"): 21.66,
}

def _norm_site(site: str | None) -> str:
    """ì—‘ì…€ ì „ì²˜ë¦¬ì™€ ë™ì¼: ì¢Œìš°ê³µë°± ì œê±°, ' forearm' -> 'forearm' ë“± í†µì¼"""
    s = (site or "").strip().lower()
    return s

def infer_skin_thickness(skin_type_label: str, skin_site: str | None, layer: str | None) -> float | None:
    """(Skin Type ë¼ë²¨, site, layer)ë¡œ Âµm ê°’ì„ ì¶”ë¡ . ê·œì¹™ ì—†ìœ¼ë©´ None."""
    stype = (skin_type_label or "").strip().lower()
    site = _norm_site(skin_site)
    lyr = (layer or "whole").strip().lower()
    if lyr not in ("whole", "epidermis"):
        lyr = "whole"
    # site ë¹„ì—ˆìœ¼ë©´ ê·œì¹™ì—ì„œ NaNì„ dorsalë¡œ ì²˜ë¦¬í–ˆë˜ ì¼€ì´ìŠ¤ë¥¼ ë°˜ì˜í•´ ê¸°ë³¸ 'dorsal'
    if not site:
        site = "dorsal"
    return SKIN_THICKNESS_RULES.get((stype, site, lyr))
    
# =========================================
# App
# =========================================

st.set_page_config(page_title='Dermal Absorption Rate(%) Prediction', page_icon='ğŸ§ª', layout='centered')
# ğŸ”¹ ì—¬ê¸°ì—ì„œ ì„¸ì…˜ ìŠ¤í† ë¦¬ì§€ ì´ˆê¸°í™”
if "raw_defaults" not in st.session_state:
    st.session_state.raw_defaults = {}
if "cat_defaults" not in st.session_state:
    st.session_state.cat_defaults = {}
    
st.title('ğŸ§ª HeteroGNN (Transformerâ†’GAT) Dermal Absorption Prediction')
st.markdown(
    """
**ëª¨ë¸ ì•ˆë‚´**  
ì´ ëª¨ë¸ì€ **ìœ íš¨ì„±ë¶„ ë„í¬ëŸ‰ 100 Âµg/cmÂ² ê¸°ì¤€**ì—ì„œ í”¼ë¶€í¡ìˆ˜ìœ¨(%) ì˜ˆì¸¡ ê°’ì„ ì œê³µí•©ë‹ˆë‹¤.
ìœ íš¨ì„±ë¶„ ë„í¬ëŸ‰ì´ ì´ì™€ í¬ê²Œ ì°¨ì´ë‚˜ëŠ” ê²½ìš° ì˜ˆì¸¡ê°’ì´ ë¶€ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì•„ë˜ì—ëŠ” ì‚¬ìš©í•  **ì‹œí—˜ ì¡°ê±´**ê³¼ **ë¬¼ì§ˆì˜ íŠ¹ì„±**ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.
"""
)

# ê³ ì • ê²½ë¡œì—ì„œ ìë™ ë¡œë“œ (ì—…ë¡œë“œ ë¶ˆí•„ìš”)
model = load_model_from_disk(DEFAULT_MODEL_PATH)
params_df = load_scaler_params_from_disk(DEFAULT_SCALER_PATH)

st.sidebar.success('ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬: ë ˆí¬ì˜ ê¸°ë³¸ íŒŒì¼ì—ì„œ ìë™ ë¡œë“œë¨')
output_raw_scale = st.sidebar.checkbox('ì¶œë ¥ê°’ì„ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜(expm1)', value=True)

PHY_CHEM = ['scaled_Molecular Weight','scaled_LogKow','scaled_TPSA','scaled_Water Solubility','scaled_Melting Point','scaled_Boiling Point','scaled_Vapor Pressure','scaled_Density','Corrosive_Irritation_score']
VEHICLE = ['Vcl_LP','Emulsifier','scaled_Enhancer_logKow','scaled_Enhancer_vap','Enhancer_ratio']
SKIN = ['Skin Type','scaled_Skin Thickness']
EXPER = ['Conc','scaled_Appl_area','scaled_Exposure Time']

RAW_FOR_SCALING = ['Molecular Weight','LogKow','TPSA','Water Solubility','Melting Point','Boiling Point','Vapor Pressure','Density','Skin Thickness','Enhancer_logKow','Enhancer_vap','Appl_area','Exposure Time']
RAW_EXTRAS = ['Init_Load_Area','Vehicle Load','Enhancer_ratio']
CATS = ['Skin Type','Vcl_LP','Corrosive_Irritation_score','Emulsifier']

# ğŸ”¹ ë¡œê·¸ë¡œ í‘œì‹œí•  ì»¬ëŸ¼(ë‚´ë¶€ í‚¤ -> UI ë¼ë²¨)
LOG_DISPLAY = {
    "Water Solubility": "log(Water Solubility)",
    "Vapor Pressure": "log(Vapor Pressure)",
}

DISPLAY_NAME = {
    "Init_Load_Area": "Active Ingredient Load per Area",
    "Vehicle Load": "Vehicle Load per Area",
}

# ë‹¨ìœ„ ì •ì˜(í•„ìš”ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
UNITS = {
    "Molecular Weight": "g/mol",
    "LogKow": "-",                # ë¬´ì°¨ì›
    "TPSA": "Ã…Â²",
    "Water Solubility": "log(mol/L)",
    "Vapor Pressure": "log(mmHg)",
    "Melting Point": "Â°C",
    "Boiling Point": "Â°C",
    "Density": "g/mL (at 20Â°C or 25Â°C)",
    "Skin Thickness": "Âµm",
    "Enhancer_logKow": "-",       # ë¬´ì°¨ì› (ê°€ì •)
    "Enhancer_vap": "log(Pa)",    # í•„ìš”ì‹œ ìˆ˜ì •
    "Appl_area": "cmÂ²",
    "Exposure Time": "h",
    "Init_Load_Area": "Âµg/cmÂ²",
    "Vehicle Load": "Âµg/cmÂ²",
    "Enhancer_ratio": "0~1"         
}

def build_label(feat: str) -> str:
    """ë‚´ë¶€ í”¼ì²˜ëª…ì„ í™”ë©´ìš© ë¼ë²¨(ë¡œê·¸ í‘œê¸° + ë‹¨ìœ„)ë¡œ ë³€í™˜"""
    base = LOG_DISPLAY.get(feat, DISPLAY_NAME.get(feat, feat))
    unit = UNITS.get(feat)
    return f"{base} ({unit})" if unit else base
    
st.header("1) í™”í•™ë¬¼ì§ˆ ê²€ìƒ‰")
q_col1, q_col2 = st.columns([2,1])
with q_col1:
    q_name = st.text_input("Chemical Name (ì •í™• ì¼ì¹˜, ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)", "")
with q_col2:
    q_cas = st.text_input("CAS (í•˜ì´í”ˆ ë¬´ì‹œ)", "")

if st.button("ê²€ìƒ‰"):
    df = load_chemical_db(PROCESSED_XLSX)
    if df is None or df.empty:
        st.info("DBê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        # ì»¬ëŸ¼ ê°€ì •: 'name', 'cas'ê°€ ì¡´ì¬
        # (í•„ìš”ì‹œ ë‹¤ë¥¸ ì´ë¦„ë„ ì¶”ê°€ ê°€ëŠ¥)
        if not {"name", "cas"}.issubset(set(df.columns)):
            st.error("ì—‘ì…€ì— 'name' ë˜ëŠ” 'cas' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            df2 = df.copy()

            # í•„í„° êµ¬ì„±
            mask = pd.Series(True, index=df2.index)
            if q_name.strip():
                mask &= df2["name"].astype(str).str.strip().str.lower() == q_name.strip().lower()
            if q_cas.strip():
                # CAS ë¹„êµ ì‹œ í•˜ì´í”ˆ ì œê±°
                norm = lambda s: str(s).replace("-", "").strip()
                mask &= df2["cas"].astype(str).map(norm) == norm(q_cas)

            hits = df2[mask]
            if hits.empty:
                st.warning("ì¼ì¹˜í•˜ëŠ” í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì²« ë²ˆì§¸ ë§¤ì¹˜ ì‚¬ìš©
                row = hits.iloc[0]
                st.success("ì¼ì¹˜ í•­ëª©ì„ ì°¾ì•˜ì–´ìš”. ê°’ì„ í¼ì— ì±„ì›Œ ë„£ì—ˆìŠµë‹ˆë‹¤.")
                st.dataframe(hits.head(5))

                # ìˆ«ì í”¼ì²˜ ê¸°ë³¸ê°’ ì£¼ì… (ì—†ëŠ” ê°’ì€ ê±´ë„ˆëœ€)
                for feat in [
                    "Molecular Weight","LogKow","TPSA","Water Solubility",
                    "Melting Point","Boiling Point","Vapor Pressure","Density"
                ]:
                    if feat in row and pd.notna(row[feat]):
                        try:
                            st.session_state.raw_defaults[feat] = float(row[feat])
                        except Exception:
                            pass

                # ì¹´í…Œê³ ë¦¬: Corrosive_Irritation_score (í…ìŠ¤íŠ¸/ìˆ«ì ëª¨ë‘ ëŒ€ì‘)
                cat = "Corrosive_Irritation_score"
                if cat in row and pd.notna(row[cat]):
                    val = row[cat]
                    mapping = LABEL_MAPS.get(cat, {})
                    # ì—‘ì…€ì— 'Positive'/'Negative' ê°™ì€ ë¼ë²¨ì¼ ê²½ìš°
                    if isinstance(val, str):
                        label = val.strip()
                        if label in mapping:
                            st.session_state.cat_defaults[cat] = label
                    else:
                        # ì½”ë“œê°€ ìˆ«ìë¡œ ìˆëŠ” ê²½ìš° â†’ ë¼ë²¨ ì—­ì¡°íšŒ
                        try:
                            code = int(val)
                            inv = {v: k for k, v in mapping.items()}
                            if code in inv:
                                st.session_state.cat_defaults[cat] = inv[code]
                        except Exception:
                            pass
                            
# í•œê³„ê°’ ë¡œë“œ (ì•± ì‹œì‘ ì‹œ 1íšŒ ìºì‹œ)
OUTLIER_LIMITS = load_outlier_limits(OUTLIERS_XLSX)

st.header('2) ì…ë ¥ ê°’')
st.caption("â€» ì…ë ¥ê°’ì€ outliers.xlsxì˜ í•˜/ìƒí•œìœ¼ë¡œ ìë™ í´ë¦¬í•‘ë©ë‹ˆë‹¤. "
           "Water Solubility / Vapor PressureëŠ” ë¡œê·¸ê°’ì„ ì…ë ¥í•˜ì„¸ìš”."
           )
st.caption("â€» í”¼ë¶€ë‘ê»˜ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ëŠ” ê²½ìš° **ê³µë€**ìœ¼ë¡œ ë‘ê³  **ì˜ˆì¸¡í•˜ê¸°**ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”."
           "ì´ëŠ” ë¨¼ì € Human/Dorsal/Whole Skin ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°ë˜ë©°, í•„ìš” ì‹œ **í”¼ë¶€ ì •ë³´ë¥¼ ë³€ê²½**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
           )


with st.form('inp'):
    colA, colB = st.columns(2)
    raw = {}
    clipped_notes = []

    # --- 2-1) Skin Thickness ì…ë ¥ ë°©ì‹ ì„ íƒ ---
    mode = st.radio(
        "Skin Thickness ì…ë ¥ ë°©ì‹",
        ["ì§ì ‘ ì…ë ¥", "ëª¨ë¦„ â†’ ê·œì¹™ìœ¼ë¡œ ìë™ê³„ì‚°"],
        index=0,
        horizontal=True
    )

    # ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ëœ ë‘ê»˜(ì—†ìœ¼ë©´ None)
    inferred_thick = None
    # ìë™ê³„ì‚° ëª¨ë“œì¼ ë•Œë§Œ íƒ€ì…/ë¶€ìœ„/ì¸µ ì„ íƒ UI ë…¸ì¶œ
    if mode.endswith("ìë™ê³„ì‚°"):
        # Skin Type ë¼ë²¨(ë‘ê»˜ ê³„ì‚°ìš©)
        stype_choices = list(LABEL_MAPS["Skin Type"].keys())
        injected = st.session_state.cat_defaults.get("Skin Type")
        stype_default_label = injected if injected in stype_choices else DEFAULT_LABELS.get("Skin Type", stype_choices[0])
        stype_idx = stype_choices.index(stype_default_label) if stype_default_label in stype_choices else 0
        sel_skin_type_label = colA.selectbox("Skin Type (ë‘ê»˜ ê³„ì‚°ìš©)", stype_choices, index=stype_idx)

        # Layer ì„ íƒ (whole/epidermis)
        sel_layer = colB.selectbox("Skin Layer", ["whole", "epidermis"], index=0)

        # Site ì„ íƒ (ì¢…ë³„ ì˜µì…˜ ì œê³µ, ì—†ìœ¼ë©´ dorsal)
        site_opts = SKIN_SITE_CANON.get(sel_skin_type_label, ["dorsal"])
        sel_site = colA.selectbox("Skin Site", site_opts, index=(site_opts.index("dorsal") if "dorsal" in site_opts else 0))

        # ê·œì¹™ ê¸°ë°˜ ë‘ê»˜ ê³„ì‚°
        inferred_thick = infer_skin_thickness(sel_skin_type_label, sel_site, sel_layer)

        # ì¹´í…Œê³ ë¦¬ ì„ íƒ ê¸°ë³¸ê°’ì—ë„ ë°˜ì˜(ì•„ë˜ CATS ë¸”ë¡ì—ì„œ ì‚¬ìš©)
        st.session_state.cat_defaults["Skin Type"] = sel_skin_type_label

        # ê³„ì‚° ê²°ê³¼ ë¹ ë¥´ê²Œ ë³´ì—¬ì£¼ê¸°
        colB.metric("ê³„ì‚°ëœ Skin Thickness (Âµm)", f"{inferred_thick:.2f}" if inferred_thick is not None else "ê·œì¹™ ì—†ìŒ")

    # --- 2-2) ìˆ˜ì¹˜ ì…ë ¥ë“¤ ---
    # 'Skin Thickness'ë§Œ ëª¨ë“œì— ë”°ë¼ ì²˜ë¦¬(ìë™ê³„ì‚°ì´ë©´ ë¹„í™œì„±/ê³ ì •, ì•„ë‹ˆë©´ ì§ì ‘ ì…ë ¥)
    for i, feat in enumerate(RAW_FOR_SCALING + RAW_EXTRAS):
        container = colA if i % 2 == 0 else colB
        default_val = float(st.session_state.raw_defaults.get(feat, 0.00))

        if feat == "Skin Thickness" and inferred_thick is not None:
            # ìë™ê³„ì‚° ëª¨ë“œ: ì½ê¸°ì „ìš©ìœ¼ë¡œ í‘œì‹œí•˜ê³  ë‚´ë¶€ ê°’ì€ ê³„ì‚°ì¹˜ ì‚¬ìš©
            container.number_input(build_label(feat), value=round(inferred_thick, 2), step=0.01, format="%.2f", disabled=True)
            val = float(inferred_thick)
        else:
            # ì¼ë°˜ ì¼€ì´ìŠ¤: ì§ì ‘ ì…ë ¥
            val = float(container.number_input(build_label(feat), value=round(default_val, 2), step=0.01, format="%.2f"))

        # outliers.xlsx ë²”ìœ„ë¡œ í´ë¦¬í•‘
        if feat in CLIP_COLS and OUTLIER_LIMITS:
            val_after, lim = clip_with_limits(feat, val, OUTLIER_LIMITS)
            if lim is not None:
                clipped_notes.append(f"{feat}: ì…ë ¥ {val:.2f} â†’ í´ë¦¬í•‘ {val_after:.2f} (ë²”ìœ„ {lim[0]} ~ {lim[1]})")
            val = val_after

        raw[feat] = val

    # --- 2-3) ì¹´í…Œê³ ë¦¬ ì…ë ¥ ---
    cat_vals = {}
    for c in CATS:
        mapping = LABEL_MAPS.get(c)

        # ìë™ê³„ì‚° ëª¨ë“œì—ì„œëŠ” 'Skin Type' ì¹´í…Œê³ ë¦¬ê°’ì„ ìœ„ ì„ íƒìœ¼ë¡œ ê³ ì •(ë³„ë„ ì…€ë ‰íŠ¸ ìˆ¨ê¹€)
        if c == "Skin Type" and mode.endswith("ìë™ê³„ì‚°"):
            cat_vals[c] = int(LABEL_MAPS[c][st.session_state.cat_defaults["Skin Type"]])
            continue

        if mapping is None:
            cat_vals[c] = int(st.number_input(f'{c} (ì •ìˆ˜ ì½”ë“œ)', value=0, step=1))
        else:
            choices = list(mapping.keys())
            injected = st.session_state.cat_defaults.get(c)
            default_label = injected if injected in choices else DEFAULT_LABELS.get(c, choices[0])
            default_idx = choices.index(default_label) if default_label in choices else 0
            sel = st.selectbox(c, choices, index=default_idx)
            cat_vals[c] = int(mapping[sel])

    submitted = st.form_submit_button('ì˜ˆì¸¡í•˜ê¸°')

# --- ì œì¶œ í›„ ---
if submitted:
    if clipped_notes:
        with st.expander("í´ë¦¬í•‘ ì ìš© ë‚´ì—­"):
            for note in clipped_notes:
                st.write("- " + note)

    conc = (raw.get('Init_Load_Area', 0.0) * raw.get('Appl_area', 0.0)) / max(raw.get('Vehicle Load', 1e-9), 1e-9)
    scaled = standardize_from_params(raw, params_df)

    x_p = [scaled.get('scaled_Molecular Weight', 0.0), scaled.get('scaled_LogKow', 0.0),
           scaled.get('scaled_TPSA', 0.0), scaled.get('scaled_Water Solubility', 0.0),
           scaled.get('scaled_Melting Point', 0.0), scaled.get('scaled_Boiling Point', 0.0),
           scaled.get('scaled_Vapor Pressure', 0.0), scaled.get('scaled_Density', 0.0),
           float(cat_vals['Corrosive_Irritation_score'])]
    x_v = [float(cat_vals['Vcl_LP']), float(cat_vals['Emulsifier']),
           scaled.get('scaled_Enhancer_logKow', 0.0), scaled.get('scaled_Enhancer_vap', 0.0),
           float(raw.get('Enhancer_ratio', 0.0))]
    x_s = [float(cat_vals['Skin Type']), scaled.get('scaled_Skin Thickness', 0.0)]
    x_e = [float(conc), scaled.get('scaled_Appl_area', 0.0), scaled.get('scaled_Exposure Time', 0.0)]

    Xp = np.array([x_p], dtype=np.float32)
    Xv = np.array([x_v], dtype=np.float32)
    Xs = np.array([x_s], dtype=np.float32)
    Xe = np.array([x_e], dtype=np.float32)

    y_pred = model.predict([Xp, Xv, Xs, Xe], verbose=0).reshape(-1)[0]
    st.subheader('ê²°ê³¼')
    st.write(f"ë¡œê·¸ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡ê°’: **{y_pred:.4f}**")
    if output_raw_scale:
        st.write(f"ì› ìŠ¤ì¼€ì¼ ì˜ˆì¸¡ê°’ (expm1): **{np.expm1(y_pred):.4f}**")

    # ì„ íƒ ë©”íƒ€ë„ í•¨ê»˜ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´:
    with st.expander('ë””ë²„ê·¸: ì…ë ¥ ë²¡í„° & ì„ íƒê°’'):
        st.json({
            'skin_meta': {
                'Mode': mode,
                # ìë™ê³„ì‚° ëª¨ë“œì¼ ë•Œë§Œ ì•„ë˜ í‚¤ê°€ ì¡´ì¬í•˜ë„ë¡ ì•ˆì „ ì²˜ë¦¬
                # (ì—†ìœ¼ë©´ Noneë¡œ í‘œê¸°)
                'Skin Type (for thickness)': st.session_state.cat_defaults.get("Skin Type"),
            },
            'x_p': dict(zip(PHY_CHEM, x_p)),
            'x_v': dict(zip(VEHICLE, x_v)),
            'x_s': dict(zip(SKIN, x_s)),
            'x_e': dict(zip(EXPER, x_e))
        })

    with st.expander('ìŠ¤ì¼€ì¼ íŒŒë¼ë¯¸í„° ìš”ì•½'):
        st.dataframe(params_df)

